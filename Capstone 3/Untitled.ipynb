{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af41614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, roc_auc_score, roc_curve, auc, f1_score, recall_score, precision_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#reproducibility\n",
    "import os\n",
    "\n",
    "rs = {'random_state': 10}\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "random_seed = 10\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Activation, Dense, Conv2D, BatchNormalization, MaxPooling2D, Flatten\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import json\n",
    "\n",
    "tf.random.set_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1227ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>mentions</th>\n",
       "      <th>emojis</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>num_proper_nouns</th>\n",
       "      <th>num_nouns</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deeds earthquake allah forgive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['#earthquake']</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>4.307692</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>['deeds', 'earthquake', 'allah', 'forgive']</td>\n",
       "      <td>['deed', 'earthquake', 'allah', 'forgive']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>near ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>['near', 'ronge', 'sask', 'canada']</td>\n",
       "      <td>['near', 'ronge', 'sask', 'canada']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>residents asked shelter notified officers shel...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>22</td>\n",
       "      <td>4.954545</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>['residents', 'asked', 'shelter', 'notified', ...</td>\n",
       "      <td>['resident', 'asked', 'shelter', 'notified', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>receive wildfires orders california</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['#wildfires']</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>['receive', 'wildfires', 'orders', 'california']</td>\n",
       "      <td>['receive', 'wildfire', 'order', 'california']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sent ruby alaska wildfires pours</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>['#Alaska', '#wildfires']</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>16</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>['sent', 'ruby', 'alaska', 'wildfires', 'pours']</td>\n",
       "      <td>['sent', 'ruby', 'alaska', 'wildfire', 'pours']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  num_hashtags  \\\n",
       "0                     deeds earthquake allah forgive       1             1   \n",
       "1                             near ronge sask canada       1             0   \n",
       "2  residents asked shelter notified officers shel...       1             0   \n",
       "3                receive wildfires orders california       1             1   \n",
       "4                   sent ruby alaska wildfires pours       1             2   \n",
       "\n",
       "                    hashtags  num_mentions mentions  emojis  num_chars  \\\n",
       "0            ['#earthquake']             0       []       0         68   \n",
       "1                         []             0       []       0         37   \n",
       "2                         []             0       []       0        130   \n",
       "3             ['#wildfires']             0       []       0         56   \n",
       "4  ['#Alaska', '#wildfires']             0       []       0         85   \n",
       "\n",
       "   num_words  mean_word_length  num_proper_nouns  num_nouns  \\\n",
       "0         13          4.307692                 0          2   \n",
       "1          7          4.428571                 0          3   \n",
       "2         22          4.954545                 0          5   \n",
       "3          7          7.142857                 0          2   \n",
       "4         16          4.375000                 0          3   \n",
       "\n",
       "                                              tokens  \\\n",
       "0        ['deeds', 'earthquake', 'allah', 'forgive']   \n",
       "1                ['near', 'ronge', 'sask', 'canada']   \n",
       "2  ['residents', 'asked', 'shelter', 'notified', ...   \n",
       "3   ['receive', 'wildfires', 'orders', 'california']   \n",
       "4   ['sent', 'ruby', 'alaska', 'wildfires', 'pours']   \n",
       "\n",
       "                                              lemmas  \n",
       "0         ['deed', 'earthquake', 'allah', 'forgive']  \n",
       "1                ['near', 'ronge', 'sask', 'canada']  \n",
       "2  ['resident', 'asked', 'shelter', 'notified', '...  \n",
       "3     ['receive', 'wildfire', 'order', 'california']  \n",
       "4    ['sent', 'ruby', 'alaska', 'wildfire', 'pours']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('tweets.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f580309",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['num_hashtags', 'hashtags', 'num_mentions',\n",
    "       'mentions', 'emojis', 'num_chars', 'num_words', 'mean_word_length',\n",
    "       'num_proper_nouns', 'num_nouns', 'tokens'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0bc7971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deeds earthquake allah forgive</td>\n",
       "      <td>1</td>\n",
       "      <td>['deed', 'earthquake', 'allah', 'forgive']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>near ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>['near', 'ronge', 'sask', 'canada']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>residents asked shelter notified officers shel...</td>\n",
       "      <td>1</td>\n",
       "      <td>['resident', 'asked', 'shelter', 'notified', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>receive wildfires orders california</td>\n",
       "      <td>1</td>\n",
       "      <td>['receive', 'wildfire', 'order', 'california']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sent ruby alaska wildfires pours</td>\n",
       "      <td>1</td>\n",
       "      <td>['sent', 'ruby', 'alaska', 'wildfire', 'pours']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                     deeds earthquake allah forgive       1   \n",
       "1                             near ronge sask canada       1   \n",
       "2  residents asked shelter notified officers shel...       1   \n",
       "3                receive wildfires orders california       1   \n",
       "4                   sent ruby alaska wildfires pours       1   \n",
       "\n",
       "                                              lemmas  \n",
       "0         ['deed', 'earthquake', 'allah', 'forgive']  \n",
       "1                ['near', 'ronge', 'sask', 'canada']  \n",
       "2  ['resident', 'asked', 'shelter', 'notified', '...  \n",
       "3     ['receive', 'wildfire', 'order', 'california']  \n",
       "4    ['sent', 'ruby', 'alaska', 'wildfire', 'pours']  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d3796fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['lemmas'].values\n",
    "y = data['target'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fac897f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train.ravel())\n",
    "y_test = label_encoder.fit_transform(y_test.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e75c19",
   "metadata": {},
   "source": [
    "First, we need to decide on the number of features for our word2vector model. We will try between 100 to 300. This will form the vector size for our word to vector models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "007f205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = 100\n",
    "model = Word2Vec(X_train,\n",
    "                 vector_size = number_of_features,\n",
    "                 window = 150,\n",
    "                 min_count = 10, \n",
    "                 workers=4, \n",
    "                 epochs=5\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bbdb7f",
   "metadata": {},
   "source": [
    "Now, we want to generate averaged word vecto features from our word2vector model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c8dd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set(model.wv.index_to_key)\n",
    "feature_vector = np.zeros((number_features,), dtypes='float64')\n",
    "num_words = 0\n",
    "for word in words:\n",
    "    if word in vocabulary:\n",
    "        num_words = num_words + 1\n",
    "        feature_vector = np.divide(feature_words, num_words)\n",
    "features = [average]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef007aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " \"'\",\n",
       " ',',\n",
       " '[',\n",
       " ']',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc7fc394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful.</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Document Category\n",
       "0                                      The sky is blue and beautiful.  weather\n",
       "1                                   Love this blue and beautiful sky!  weather\n",
       "2                        The quick brown fox jumps over the lazy dog.  animals\n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n",
       "4                         I love green eggs, ham, sausages and bacon!     food\n",
       "5                    The brown fox is quick and the blue dog is lazy!  animals\n",
       "6            The sky is very blue and the sky is very beautiful today  weather\n",
       "7                         The dog is lazy but the brown fox is quick!  animals"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "corpus = ['The sky is blue and beautiful.',\n",
    "          'Love this blue and beautiful sky!',\n",
    "          'The quick brown fox jumps over the lazy dog.',\n",
    "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
    "          'I love green eggs, ham, sausages and bacon!',\n",
    "          'The brown fox is quick and the blue dog is lazy!',\n",
    "          'The sky is very blue and the sky is very beautiful today',\n",
    "          'The dog is lazy but the brown fox is quick!'    \n",
    "]\n",
    "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']\n",
    "\n",
    "corpus = np.array(corpus)\n",
    "corpus_df = pd.DataFrame({'Document': corpus, \n",
    "                          'Category': labels})\n",
    "corpus_df = corpus_df[['Document', 'Category']]\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf086679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\ProgramData\\Anaconda3\\lib\\nltk_data...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Access is denied: 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data\\\\corpora\\\\stopwords.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-eb13a0419bc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopwords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[0;32m    777\u001b[0m                 )\n\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mincr_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo_or_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[1;31m# Error messages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mErrorMessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\u001b[0m in \u001b[0;36mincr_download\u001b[1;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# Handle Packages (delegate to a helper function).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_download_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\u001b[0m in \u001b[0;36m_download_package\u001b[1;34m(self, info, download_dir, force)\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTALE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mStaleMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;31m# Ensure the download_dir exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Access is denied: 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data\\\\corpora\\\\stopwords.zip'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbcdc02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
