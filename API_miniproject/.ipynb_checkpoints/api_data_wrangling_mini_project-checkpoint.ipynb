{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from https://data.nasdaq.com/ (formerly Quandl API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will need to register a free account on the https://data.nasdaq.com/ website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you register, you will be provided with a unique API key, that you should store:\n",
    "\n",
    "*Note*: Use a `.env` file and put your key in there and `python-dotenv` to access it in this notebook. \n",
    "\n",
    "The code below uses a key that was used when generating this project but has since been deleted. Never submit your keys to source control. There is a `.env-example` file in this repository to illusrtate what you need. Copy that to a file called `.env` and use your own api key in that `.env` file. Make sure you also have a `.gitignore` file with a line for `.env` added to it. \n",
    "\n",
    "The standard Python gitignore is [here](https://github.com/github/gitignore/blob/master/Python.gitignore) you can just copy that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# get api key from your .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('NASDAQ_API_KEY')\n",
    "\n",
    "print(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasdaq Data has a large number of data sources, but, unfortunately, most of them require a Premium subscription. Still, there are also a good number of free datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this mini project, we will focus on equities data from the Frankfurt Stock Exhange (FSE), which is available for free. We'll try and analyze the stock prices of a company called Carl Zeiss Meditec, which manufactures tools for eye examinations, as well as medical lasers for laser eye surgery: https://www.zeiss.com/meditec/int/home.html. The company is listed under the stock ticker AFX_X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the detailed Nasdaq Data API instructions here: https://docs.data.nasdaq.com/docs/in-depth-usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a dedicated Python package for connecting to the Nasdaq API, we would prefer that you use the *requests* package, which can be easily downloaded using *pip* or *conda*. You can find the documentation for the package here: http://docs.python-requests.org/en/master/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apart from the *requests* package, you are encouraged to not use any third party Python packages, such as *pandas*, and instead focus on what's available in the Python Standard Library (the *collections* module might come in handy: https://pymotw.com/3/collections/).\n",
    "Also, since you won't have access to DataFrames, you are encouraged to us Python's native data structures - preferably dictionaries, though some questions can also be answered using lists.\n",
    "You can read more on these data structures here: https://docs.python.org/3/tutorial/datastructures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the JSON responses you will be getting from the API map almost one-to-one to Python's dictionaries. Unfortunately, they can be very nested, so make sure you read up on indexing dictionaries in the documentation provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the relevant modules\n",
    "import requests\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: API's can change a bit with each version, for this exercise it is reccomended to use the nasdaq api at `https://data.nasdaq.com/api/v3/`. This is the same api as what used to be quandl so `https://www.quandl.com/api/v3/` should work too.\n",
    "\n",
    "Hint: We are looking for the `AFX_X` data on the `datasets/FSE/` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, call the Nasdaq API and pull out a small sample of the data (only one day) to get a glimpse\n",
    "# into the JSON structure that will be returned\n",
    "url = 'https://data.nasdaq.com/api/v3/datasets/FSE/AFX_X/data.json'\n",
    "response = requests.get(url)\n",
    "#check import was with no errors\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data as a dictionary \n",
    "json_data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the imported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['dataset_data'])\n"
     ]
    }
   ],
   "source": [
    "#double check that the data is a dictionary \n",
    "print(type(json_data))\n",
    "#get the names of keys\n",
    "print(json_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the JSON structure of the object you created, and take note of how nested it is,\n",
    "# as well as the overall structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['limit', 'transform', 'column_index', 'column_names', 'start_date', 'end_date', 'frequency', 'data', 'collapse', 'order'])\n",
      "2000-06-07\n",
      "2020-12-01\n",
      "[['2020-12-01', 112.2, 112.2, 111.5, 112.0, None, 51.0, 5703.0, None, None, None], ['2020-11-30', 111.0, 113.6, 111.0, 112.1, None, 315.0, 35111.5, None, None, None]]\n"
     ]
    }
   ],
   "source": [
    "#we expect to see nested dictionaries \n",
    "#so this is to get the names of the inner keys\n",
    "print(json_data['dataset_data'].keys())\n",
    "#time period is from 2000 to 2020\n",
    "print(json_data['dataset_data']['start_date'])\n",
    "print(json_data['dataset_data']['end_date'])\n",
    "print(json_data['dataset_data']['data'][0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect data from the Frankfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).\n",
    "url_2017 = 'https://data.nasdaq.com/api/v3/datasets/FSE/AFX_X/data.json?start_date=2017-01-01&end_date=2017-12-31&api_key='+API_KEY\n",
    "response_2017 = requests.get(url_2017)\n",
    "#double check that import is without errors\n",
    "response_2017.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert the returned JSON object into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['limit', 'transform', 'column_index', 'column_names', 'start_date', 'end_date', 'frequency', 'data', 'collapse', 'order'])\n",
      "2017-01-01\n",
      "2017-12-31\n"
     ]
    }
   ],
   "source": [
    "#convert JSON object to python dictionary \n",
    "data_2017 = response_2017.json()\n",
    "#confirm JSON object is a python dictionary \n",
    "print(type(data_2017))\n",
    "#check keys\n",
    "print(data_2017['dataset_data'].keys())\n",
    "#check we have the right data set\n",
    "print(data_2017['dataset_data']['start_date'])\n",
    "print(data_2017['dataset_data']['end_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Calculate what the highest and lowest opening prices were for the stock in this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem: we are looking for the opening prices but we don't actually oepning prices as a key\n",
    "#Solution: we need to explore the keys more as we know this will be a nested dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover']\n",
      "[['2017-12-29', 51.76, 51.94, 51.45, 51.76, None, 34640.0, 1792304.0, None, None, None], ['2017-12-28', 51.65, 51.82, 51.43, 51.6, None, 40660.0, 2099024.0, None, None, None]]\n"
     ]
    }
   ],
   "source": [
    "print(data_2017['dataset_data']['column_names'])\n",
    "print(data_2017['dataset_data']['data'][0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us that the second column is the opening prices, so index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all the opening prices for 2017\n",
    "opening_prices = []\n",
    "for values in data_2017['dataset_data']['data']:\n",
    "    opening_prices.append(values[1])\n",
    "#check if there are any values that are not numbers\n",
    "#None in opening_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum opening price for Carl Zeiss Meditec in 2017 was $34.0\n",
      "The maximum opening price for Carl Zeiss Meditec in 2017 was $53.11\n"
     ]
    }
   ],
   "source": [
    "#list of only opening prices which are floats\n",
    "opening_prices_floats = []\n",
    "for items in opening_prices:\n",
    "    if type(items)== float:\n",
    "        opening_prices_floats.append(items)\n",
    "print(\"The minimum opening price for Carl Zeiss Meditec in 2017 was $\" + str(min(opening_prices_floats)))\n",
    "print(\"The maximum opening price for Carl Zeiss Meditec in 2017 was $\" + str(max(opening_prices_floats)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What was the largest change in any one day (based on High and Low price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_high_prices = []\n",
    "daily_low_prices = []\n",
    "for values in data_2017['dataset_data']['data']:\n",
    "    daily_high_prices.append(values[2])\n",
    "    daily_low_prices.append(values[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRun this cell only to run checks. \\n\\n#check if there are any none values in the daily high prices and daily low prices\\nprint(None in daily_high_prices)\\nprint(None in daily_low_prices)\\n#make sure the lenghts of the two lists are the same so we can subtract corresponding values\\nprint(len(daily_high_prices))\\nprint(len(daily_low_prices))\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Run this cell only to run checks. \n",
    "\n",
    "#check if there are any none values in the daily high prices and daily low prices\n",
    "print(None in daily_high_prices)\n",
    "print(None in daily_low_prices)\n",
    "#make sure the lenghts of the two lists are the same so we can subtract corresponding values\n",
    "print(len(daily_high_prices))\n",
    "print(len(daily_low_prices))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change in stock prices for any one day for Carl Zeiss Meditec in 2017 was $2.81\n"
     ]
    }
   ],
   "source": [
    "daily_change = []\n",
    "for values in data_2017['dataset_data']['data']:\n",
    "    if type(values[2]) == float and type(values[3]) == float:\n",
    "        change_in_price =(values[2] - values[3])\n",
    "        daily_change.append(change_in_price)\n",
    "max_change = \"%.2f\"%max(daily_change)                \n",
    "           \n",
    "print(\"The largest change in stock prices for any one day for Carl Zeiss Meditec in 2017 was $\" + str(max_change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What was the largest change between any two days (based on Closing Price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing_prices_floats = []\n",
    "date = []\n",
    "for values in data_2017['dataset_data']['data']:\n",
    "    #we only want the dates where the closing and opening prices are floats\n",
    "    if type(values[1])== float and type(values[4])==float:\n",
    "        date.append(values[0])\n",
    "        closing_prices_floats.append(values[4])\n",
    "#len(closing_prices_floats)\n",
    "#len(date)\n",
    "#len(opening_prices_floats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have lists of opening, closing prices, and dates. To calculate the price change over two days we need to subtract the closing price of a day from the opening prices of the previous date. \n",
    "At the moment the dates are in decending order: starting from December and going down to January, as are the values for opening and closing. \n",
    "\n",
    "Assumption: we are looking for the maximum change between two consecutive dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.reverse()\n",
    "opening_prices_floats.reverse()\n",
    "closing_prices_floats.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change in stock prices over two consecutive days for Carl Zeiss Meditec in 2017 was $2.17\n"
     ]
    }
   ],
   "source": [
    "change_over_cons_days = []\n",
    "for i in range(len(closing_prices_floats)):\n",
    "    if i <= 250:\n",
    "        change = closing_prices_floats[i+1] - opening_prices_floats[i]\n",
    "        change_over_cons_days.append(change)\n",
    "max_change_cons_days = \"%.2f\"%max(change_over_cons_days)        \n",
    "print(\"The largest change in stock prices over two consecutive days for Carl Zeiss Meditec in 2017 was $\" + str(max_change_cons_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change in stock prices over any two days for Carl Zeiss Meditec in 2017 was $0.78\n"
     ]
    }
   ],
   "source": [
    "change_over_cons_days = []\n",
    "for i in range(len(closing_prices_floats)):\n",
    "    if i != 0:\n",
    "        change = opening_prices_floats[i] - closing_prices_floats[i-1]\n",
    "        change_over_cons_days.append(change)\n",
    "max_change_cons_days = \"%.2f\"%max(change_over_cons_days)        \n",
    "print(\"The largest change in stock prices over any two days for Carl Zeiss Meditec in 2017 was $\" + str(max_change_cons_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What was the average daily trading volume during this year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking where to find the traded volume\n",
    "#print(data_2017['dataset_data']['column_names'])\n",
    "#print(data_2017['dataset_data']['data'][0:2])\n",
    "#print(data_2017['dataset_data']['column_names'][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traded volume is index 6. \n",
    "daily_traded_volumes = []\n",
    "#extract traded values\n",
    "for values in data_2017['dataset_data']['data']:\n",
    "    daily_traded_volumes.append(values[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run this cell to check the type of data in daily_traded_volumes is only float \n",
    "types = []\n",
    "for item in daily_traded_volumes:\n",
    "    types.append(type(item))\n",
    "print(set(types))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average daily volume of stocks for Carl Zeiss Meditec in 2017 was 89124.34\n"
     ]
    }
   ],
   "source": [
    "#Average is the sum of all the elements in the list / the total number of elements in the list \n",
    "average_daily_traded_volume = sum(daily_traded_volumes)/len(daily_traded_volumes)\n",
    "#to neaten up to 2dp\n",
    "rounded_average = \"%.2f\"%average_daily_traded_volume        \n",
    "print(\"The average daily volume of stocks for Carl Zeiss Meditec in 2017 was \" + str(rounded_average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median daily traded volume of stocks for Carl Zeizz Meditec in 2017 was 76600.0\n"
     ]
    }
   ],
   "source": [
    "#to work out the median we need to first sort the list in ascending order\n",
    "ascending_traded_volumes = sorted(daily_traded_volumes) \n",
    "#we want to find the item in the list which is the middle index: so len(list)/2 should give us the middle value.\n",
    "#we know the length of the list will be 255 so we need to round up for the 128th index\n",
    "median = ascending_traded_volumes[round(len(ascending_traded_volumes)/2)]\n",
    "print(\"The median daily traded volume of stocks for Carl Zeizz Meditec in 2017 was \" + str(median))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7635eb1b9d0fe97add78a7368b6b431c09bb8ad5c42e437d64abdd99821c31ae"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
